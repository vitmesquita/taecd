{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549130bc",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Compared to last week, this is a very simple lab <span style=\"font-size:20pt;\">ðŸ˜ƒ</span>\n",
    "\n",
    "You will implement the [Classification and Regression Tree (CART)](https://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees_.28CART.29) algorithm from scratch.\n",
    "\n",
    "The lab is broken down into the following pieces:\n",
    "\n",
    "* Gini Index\n",
    "* Creating Splits\n",
    "* Buiding a Tree\n",
    "* Making a prediction\n",
    "\n",
    "## Exercise 1 -- Download and load the dataset\n",
    "\n",
    "This time, we will be using the banknote authentication data set, which is available to download from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/banknote+authentication)\n",
    "\n",
    "* Download the file\n",
    "* Read it and make a scikit-learn style dataset from it\n",
    "* Make a 70/30 train test split\n",
    "\n",
    "**TIP:** Pandas can readl URLs directly (But it's still nice to have the dataset locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce95e159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:26.867460Z",
     "start_time": "2021-06-20T20:34:24.427555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt', names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])\n",
    "\n",
    "X = data.loc[:, data.columns != 'class'].values\n",
    "y = data['class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9560fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:26.899458Z",
     "start_time": "2021-06-20T20:34:26.870535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699      0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210      0\n",
       "2      3.86600  -2.63830    1.9242  0.10645      0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440      0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880      0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfdb95",
   "metadata": {},
   "source": [
    "## Exercise 2 -- Gini Index\n",
    "\n",
    "Implement the Gini Index function, which will be used later on as the criterion to create splits.\n",
    "\n",
    "Please, don't use an existing implementation, refer to the [book](https://www.statlearning.com/s/ISLRSeventhPrinting.pdf), and if you need help, as questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efed083a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.073105Z",
     "start_time": "2021-06-20T20:34:26.901452Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_index(region):\n",
    "    \"\"\"\n",
    "    Implements the gini index over the classes in a region\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : array (1D)\n",
    "        array of labels assigned to points in this region\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        the Gini Index\n",
    "    \"\"\"\n",
    "    classes = np.unique(region)\n",
    "    N = region.shape[0]\n",
    "    gini = 0\n",
    "    for c in classes:\n",
    "        p = (region == c).sum() / N\n",
    "        gini += p*(1-p)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682c61d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.165408Z",
     "start_time": "2021-06-20T20:34:27.075084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.495, 0.0, 0.0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code\n",
    "np.random.seed(0)\n",
    "gini_index(np.random.randint(0, 2, 20)), gini_index(np.ones(10)), gini_index(np.zeros(10)), gini_index(np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25898d48",
   "metadata": {},
   "source": [
    "## Exercise 3 -- Make a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f49195e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.285039Z",
     "start_time": "2021-06-20T20:34:27.166401Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_region(region, feature_index, tau):\n",
    "    \"\"\"\n",
    "    Given a region, splits it based on the feature indicated by\n",
    "    `feature_index`, the region will be split in two, where\n",
    "    one side will contain all points with the feature with values \n",
    "    lower than `tau`, and the other split will contain the \n",
    "    remaining datapoints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : array of size (n_samples, n_features)\n",
    "        a partition of the dataset (or the full dataset) to be split\n",
    "    feature_index : int\n",
    "        the index of the feature used to make this partition\n",
    "    tau : float\n",
    "        The threshold used to make this partition\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    low_partition : array\n",
    "        indices of the datapoints in `region` where feature < `tau`\n",
    "    high_partition : array\n",
    "        indices of the datapoints in `region` where feature < `tau` \n",
    "    \"\"\"\n",
    "    return np.where(region[:, feature_index] < tau)[0], np.where(region[:, feature_index] >= tau)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387ad2d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.409616Z",
     "start_time": "2021-06-20T20:34:27.286183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324,) (636,)\n"
     ]
    }
   ],
   "source": [
    "r, l = split_region(X_train, 1, 0)\n",
    "print(r.shape, l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b62ea4",
   "metadata": {},
   "source": [
    "## Exercise 4 -- Find the best split\n",
    "\n",
    "The strategy is quite simple (as well as inefficient), but it helps to reinforce the concepts.\n",
    "We are going to use a greedy, exhaustive algorithm to select splits, selecting the `feature_index` and the `tau` that minimizes the Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9769abde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.493073Z",
     "start_time": "2021-06-20T20:34:27.414547Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_split(X, y):\n",
    "    \"\"\"\n",
    "    Given a dataset (full or partial), splits it on the feature of that minimizes the Gini Index\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array (n_samples, n_features)\n",
    "        features \n",
    "    y : array (n_samples, )\n",
    "        labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    decision : dictionary\n",
    "        keys are:\n",
    "        * 'feature_index' -> an integer that indicates the feature of `X` on which the data is split\n",
    "        * 'tau' -> the threshold used to make the split\n",
    "        * 'low_region' -> array of indices where the `feature_index`th feature of X is lower than `tau`\n",
    "        * 'high_region' -> indices not in `low_region`\n",
    "    \"\"\"\n",
    "    best_gini = 100 # unreasonably high Gini Index\n",
    "    best_feature_index = None\n",
    "    best_tau = None\n",
    "    best_lo = None\n",
    "    best_hi = None\n",
    "    for feature_index in range(X.shape[1]):\n",
    "        for tau in X[:, feature_index]:\n",
    "            lo, hi = split_region(X, feature_index, tau)\n",
    "            gini = gini_index(y[lo]) + gini_index(y[hi])\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_feature_index = feature_index\n",
    "                best_tau = tau\n",
    "                best_lo = lo\n",
    "                best_hi = hi\n",
    "    return {\n",
    "        'feature_index': best_feature_index,\n",
    "        'tau': best_tau,\n",
    "        'low_region' : best_lo,\n",
    "        'high_region' : best_hi,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee50d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.590573Z",
     "start_time": "2021-06-20T20:34:27.498650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_index': 1,\n",
       " 'tau': 9.1214,\n",
       " 'low_region': array([1, 2, 3, 4], dtype=int64),\n",
       " 'high_region': array([0], dtype=int64)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split(X_train[:5], y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3526dcb",
   "metadata": {},
   "source": [
    "## Exercise 5 -- Recursive Splitting\n",
    "\n",
    "The test above is an example on how to find the root node of our decision tree. The algorithm now is a greedy search until we reach a stop criterion.\n",
    "\n",
    "The trivial stopping criterion is to recursively grow the tree until each split contains points for a single class (perfect node purity). For trainin, that normally means we are overfitting.\n",
    "\n",
    "You will implement these criteria to stop the growth:\n",
    "\n",
    "* A node is a leaf if:\n",
    "    * It has less than `min_samples` datapoints\n",
    "    * It is at the `max_depth` level from the root (each split creates a new level)\n",
    "    * Gini Index is `0`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effea9cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.675630Z",
     "start_time": "2021-06-20T20:34:27.592708Z"
    }
   },
   "outputs": [],
   "source": [
    "def recursive_growth(node, min_samples, max_depth, current_depth, X, y):\n",
    "    \"\"\"\n",
    "    Recursively grows a decision tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : dictionary\n",
    "        If the node is terminal, it contains only the \"class\" key, which determines the value to be used as a prediction.\n",
    "        If the node is not terminal, the dictionary has the structure defined by `get_split`\n",
    "    min_samples : int\n",
    "        parameter for stopping criterion\n",
    "    max_depth : int\n",
    "        parameter for stopping criterion\n",
    "    depth : int\n",
    "        current distance from the root\n",
    "    X : array (n_samples, n_features)\n",
    "        features (full dataset)\n",
    "    y : array (n_samples, )\n",
    "        labels (full dataset)\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    To create a terminal node, a dictionary is created with a single \"class\" key, and a value that is\n",
    "    the class to which the majority of the datapoins in the node belong.\n",
    "    \n",
    "    'left' and 'right' keys are added to non-terminal nodes, which contain (possibly terminal) nodes \n",
    "    from higher levels of the tree:\n",
    "    'left' corresponds to the 'low_region' key, and 'right' to the 'high_region' key\n",
    "    \"\"\"\n",
    "    if 'low_region' in node.keys(): # not a terminal node\n",
    "        lo = node['low_region']\n",
    "        hi = node['high_region']\n",
    "        # process left\n",
    "        classes, counts = np.unique(y[lo], return_counts=True)\n",
    "        if len(lo) < min_samples or current_depth == max_depth or len(classes) == 1:\n",
    "            node['left'] = {'class':classes[np.argmax(counts)]}\n",
    "        else:\n",
    "            node['left'] = get_split(X[lo], y[lo])\n",
    "            recursive_growth(node['left'], min_samples, max_depth, current_depth + 1, X, y)\n",
    "\n",
    "        # process right\n",
    "        classes, counts = np.unique(y[hi], return_counts=True)\n",
    "        if len(hi) < min_samples or current_depth == max_depth or len(classes) == 1:\n",
    "            node['right'] = {'class':classes[np.argmax(counts)]}\n",
    "        else:\n",
    "            node['right'] = get_split(X[hi], y[hi])\n",
    "            recursive_growth(node['right'], min_samples, max_depth, current_depth + 1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da4a74a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.791503Z",
     "start_time": "2021-06-20T20:34:27.678904Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 20\n",
    "test_root = get_split(X_train[:k, :], y_train[:k])\n",
    "recursive_growth(test_root, 5, 10, 1, X_train[:k, :], y_train[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159d6600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.852939Z",
     "start_time": "2021-06-20T20:34:27.794011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_index': 0,\n",
       " 'tau': 0.94225,\n",
       " 'low_region': array([ 0,  1,  2,  3,  4,  6,  8,  9, 11, 12, 14, 16, 17], dtype=int64),\n",
       " 'high_region': array([ 5,  7, 10, 13, 15, 18, 19], dtype=int64),\n",
       " 'left': {'feature_index': 1,\n",
       "  'tau': 6.8741,\n",
       "  'low_region': array([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12], dtype=int64),\n",
       "  'high_region': array([0, 8], dtype=int64),\n",
       "  'left': {'feature_index': 0,\n",
       "   'tau': 0.94225,\n",
       "   'low_region': array([ 0,  1,  2,  3,  5,  7,  9, 10], dtype=int64),\n",
       "   'high_region': array([4, 6, 8], dtype=int64),\n",
       "   'left': {'feature_index': 0,\n",
       "    'tau': 0.94225,\n",
       "    'low_region': array([0, 1, 2, 3, 6], dtype=int64),\n",
       "    'high_region': array([4, 5, 7], dtype=int64),\n",
       "    'left': {'feature_index': 1,\n",
       "     'tau': 9.1214,\n",
       "     'low_region': array([1, 2, 3, 4], dtype=int64),\n",
       "     'high_region': array([0], dtype=int64),\n",
       "     'left': {'class': 1},\n",
       "     'right': {'class': 0}},\n",
       "    'right': {'class': 0}},\n",
       "   'right': {'class': 1}},\n",
       "  'right': {'class': 0}},\n",
       " 'right': {'class': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a76bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:27.930898Z",
     "start_time": "2021-06-20T20:34:27.854586Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(node, depth):\n",
    "    if 'class' in node.keys():\n",
    "        print('.  '*(depth-1), f\"[{node['class']}]\")\n",
    "    else:\n",
    "        print('.  '*depth, f'X_{node[\"feature_index\"]} < {node[\"tau\"]}')\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e950b741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:28.026993Z",
     "start_time": "2021-06-20T20:34:27.932888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_0 < 0.94225\n",
      ".   X_1 < 6.8741\n",
      ".  .   X_0 < 0.94225\n",
      ".  .  .   X_0 < 0.94225\n",
      ".  .  .  .   X_1 < 9.1214\n",
      ".  .  .  .   [1]\n",
      ".  .  .  .   [0]\n",
      ".  .  .   [0]\n",
      ".  .   [1]\n",
      ".   [0]\n",
      " [0]\n"
     ]
    }
   ],
   "source": [
    "print_tree(test_root, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf558dc8",
   "metadata": {},
   "source": [
    "# Exercise 6 -- Make a Prediction\n",
    "Use the test_node to predict the class of a compatible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e4f957d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:28.156544Z",
     "start_time": "2021-06-20T20:34:28.030998Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sample(node, sample):\n",
    "    \"\"\"\n",
    "    Makes a prediction based on the decision tree defined by `node`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : dictionary\n",
    "        A node created one of the methods above\n",
    "    sample : array of size (n_features,)\n",
    "        a sample datapoint\n",
    "    \"\"\"\n",
    "    if 'class' in node.keys():\n",
    "        return node['class']\n",
    "    if sample[node['feature_index']] < node['tau']:\n",
    "        return predict_sample(node['left'], sample)\n",
    "    return predict_sample(node['right'], sample)\n",
    "        \n",
    "def predict(node, X):\n",
    "    \"\"\"\n",
    "    Makes a prediction based on the decision tree defined by `node`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : dictionary\n",
    "        A node created one of the methods above\n",
    "    X : array of size (n_samples, n_features)\n",
    "        n_samples predictions will be made\n",
    "    \"\"\"\n",
    "    prediction = np.zeros(X.shape[0])\n",
    "    for i, sample in enumerate(X):\n",
    "        prediction[i] = predict_sample(node, sample)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83680c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:34:30.078267Z",
     "start_time": "2021-06-20T20:34:28.157545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.31666666666666665\n",
      "Test accuracy : 0.3179611650485437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "root = get_split(X_train, y_train)\n",
    "recursive_growth(root, 20, 10, 1, X_train, y_train)\n",
    "test_acc = accuracy_score(y_test, predict(root, X_test))\n",
    "train_acc = accuracy_score(y_train, predict(root, X_train))\n",
    "\n",
    "print(f'Train accuracy : {train_acc}')\n",
    "print(f'Test accuracy : {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06090ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:37:48.352699Z",
     "start_time": "2021-06-20T20:37:48.075257Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('max.columns',500)\n",
    "\n",
    "# leitura dos dados - vamos fazer a leitura de dois arquivos: adult.data e adult.test\n",
    "# assim teremos o mesmo nÃºmero de registros do dado como descrito no site fonte\n",
    "dataset1 = pd.read_csv('adult.data',sep=',',header=None)\n",
    "dataset2 = pd.read_csv('adult.test',sep=',',skiprows=1,header=None,)\n",
    "\n",
    "dataset = pd.concat([dataset1,dataset2],axis=0)\n",
    "dataset.columns = [\n",
    "    'age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "    'occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week',\n",
    "    'native-country','label'\n",
    "]\n",
    "\n",
    "# colunas numericas\n",
    "num_cols = ['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "# colunas categoricas\n",
    "cat_cols = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country']\n",
    "# variavel objetivo\n",
    "label = 'label'\n",
    "# dataset legivel pelo sklearn\n",
    "X = pd.get_dummies(dataset.drop('label',axis=1),columns=cat_cols,drop_first=True).values\n",
    "y = (dataset['label'].str.contains('>50K')).astype(int).values\n",
    "\n",
    "# split treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bacc83e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:37:51.584342Z",
     "start_time": "2021-06-20T20:37:51.576403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(976, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729fd5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:38:23.382038Z",
     "start_time": "2021-06-20T20:38:13.866022Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-827d927136bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecursive_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-1f2e1db14cf5>\u001b[0m in \u001b[0;36mrecursive_growth\u001b[1;34m(node, min_samples, max_depth, current_depth, X, y)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mrecursive_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_depth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# process right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1f2e1db14cf5>\u001b[0m in \u001b[0;36mrecursive_growth\u001b[1;34m(node, min_samples, max_depth, current_depth, X, y)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcurrent_depth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m     \"\"\"\n\u001b[1;32m-> 1193\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "root = get_split(X_train, y_train)\n",
    "recursive_growth(root, 100, 10, 1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(root, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
